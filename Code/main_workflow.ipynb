{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompts\n",
    "\n",
    "FEW_SHOT_ATOMIC_VERDICT = '''\n",
    "You are a helpful AI assistant answering medical and clinical questions.\n",
    "\n",
    "You will be given an input medical case, input question, a statement that is related to the question, and input context related to the statement. \n",
    "Based on the given input question and input context, is the statement true or false? Please only refer to the veracity of the given statement, not the veracity of the whole question.\n",
    "Please only answer with TRUE or FALSE.\n",
    "\n",
    "########\n",
    "    \n",
    "INPUT QUESTION:\n",
    "A patient with metastatic CRPC is unable to tolerate the standard 1000 mg/day dose of abiraterone due to financial constraints. What alternative dosing strategy could be considered?\n",
    "\n",
    "INPUT CONTEXT:\n",
    "Abiraterone can be given at 250 mg/day and administered following a low- fat breakfast as an alternative to the dose of 1000 mg/day after an overnight fast.\n",
    "\n",
    "STATEMENT:\n",
    "An alternative dosing strategy exists for a patient with metastatic castration-resistant prostate cancer (CRPC) who cannot tolerate the standard 1000 mg/day dose of abiraterone due to financial constraints.\n",
    "\n",
    "Is the given statement TRUE or FALSE based on question and context? The statement is: TRUE\n",
    "\n",
    "########\n",
    "\n",
    "INPUT QUESTION:\n",
    "A patient with metastatic CRPC is unable to tolerate the standard 1000 mg/day dose of abiraterone due to financial constraints. What alternative dosing strategy could be considered?\n",
    "\n",
    "INPUT CONTEXT:\n",
    "Therefore, abiraterone can be given at 250 mg/day administered following a low-fat breakfast, as an alternative to the dose of 1000 mg/day after an overnight fast in patients who will not take or cannot afford the standard dose. The cost savings may reduce financial toxicity and improve adherence.\n",
    "\n",
    "STATEMENT:\n",
    "Taking abiraterone with a low-fat breakfast may help improve adherence.\n",
    "\n",
    "Is the given statement TRUE or FALSE based on question and context? The statement is: FALSE\n",
    "\n",
    "########\n",
    "\n",
    "INPUT QUESTION:\n",
    "A patient with a newly diagnosed prostate cancer has a clinical stage of T2c, 50% biopsy cores positive, PSA of 6 ng/ml and a Gleason score of 7a. How might the NCCN risk stratification schema categorize this patient?\n",
    "\n",
    "INPUT CONTEXT:\n",
    "Clinicians should use clinical T stage, serum PSA, Grade Group (Gleason score), and tumor volume on biopsy to risk stratify patients with newly diagnosed prostate cancer\n",
    "\n",
    "STATEMENT:\n",
    "The risk-classification is based on the combination of clinical stage, Gleason score, and PSA level.\n",
    "\n",
    "Is the given statement TRUE or FALSE based on question and context? The statement is: TRUE\n",
    "\n",
    "########\n",
    "\n",
    "INPUT QUESTION:\n",
    "A patient with a newly diagnosed prostate cancer has a clinical stage of T2c, 50% biopsy cores positive, PSA of 6 ng/ml and a Gleason score of 7a. How might the NCCN risk stratification schema categorize this patient?\n",
    "\n",
    "INPUT CONTEXT:\n",
    "Specifically, the NCCN Guidelines subdivide intermediate-risk disease into favourable and unfavourable intermediate-risk, with unfavourable features including ISUP grade group 3, and/or ≥ 50% positive systematic biopsy cores and/or at least two intermediate-risk factors. Intermediate risk factors are cT2b–cT2c, Grade Group 2 or, 3 PSA 10–20 ng/mL.\n",
    "\n",
    "STATEMENT:\n",
    "The patient would be categorized as intermediate-risk.\n",
    "\n",
    "Is the given statement TRUE or FALSE based on question and context? The statement is: FALSE\n",
    "\n",
    "########\n",
    "\n",
    "INPUT QUESTION:\n",
    "How do I treat a patient according to the ASCENDE-RT trial?\n",
    "\n",
    "INPUT CONTEXT:\n",
    "The randomized ASCENDE-RT trial compared two methods of dose escalation in 398 patients with intermediate- or high-risk prostate cancer: dose-escalated EBRT boost to 78 Gy or LDR brachytherapy boost. All patients were initially treated with 12 months of ADT and pelvic EBRT to 46 Gy.\n",
    "\n",
    "STATEMENT:\n",
    "All patients previously recieved 12 months of ADT and EBRT to 46 Gy.\n",
    "\n",
    "Is the given statement TRUE or FALSE based on question and context? The statement is: TRUE\n",
    "\n",
    "########\n",
    "\n",
    "INPUT QUESTION:\n",
    "How do I treat a patient according to the ASCENDE-RT trial?\n",
    "\n",
    "INPUT CONTEXT:\n",
    "The randomized ASCENDE-RT trial compared two methods of dose escalation in 398 patients with intermediate- or high-risk prostate cancer: dose-escalated EBRT boost to 78 Gy or LDR brachytherapy boost. All patients were initially treated with 12 months of ADT and pelvic EBRT to 46 Gy\n",
    "\n",
    "STATEMENT:\n",
    "According to the ASCENDE-RT trial, patients with biochemical recurrence (BCR) after radical prostatectomy should be treated with early salvage radiotherapy (SRT) combined with androgen deprivation therapy (ADT).\n",
    "\n",
    "Is the given statement TRUE or FALSE based on question and context? The statement is: FALSE\n",
    "\n",
    "########\n",
    "\n",
    "INPUT QUESTION:\n",
    "A 55-year-old man with a life expectancy of over 10 years has been diagnosed with very low-risk prostate cancer. What management strategy is recommended for him according to the NCCN guidelines?\n",
    "\n",
    "INPUT CONTEXT:\n",
    "At this time, the NCCN Panel consensus is that active surveillance is preferred for all patients with very-low-risk prostate cancer and life expectancy greater than 10 years.\n",
    "\n",
    "STATEMENT:\n",
    "Active surveillance is preferred for patients with very low-risk prostate cancer.\n",
    "\n",
    "Is the given statement TRUE or FALSE based on question and context? The statement is: TRUE\n",
    "\n",
    "########\n",
    "\n",
    "INPUT QUESTION:\n",
    "A 55-year-old man with a life expectancy of over 10 years has been diagnosed with very low-risk prostate cancer. What management strategy is recommended for him according to the NCCN guidelines?\n",
    "\n",
    "INPUT CONTEXT:\n",
    "Active surveillance is preferred for patients with very-low-risk prostate cancer and a life expectancy\n",
    "≥10 years. (Observation is preferred for patients with a life expectancy <10 years and very-low-risk disease.) Active surveillance is preferred for most patients with low-risk prostate cancer and a life expectancy ≥10 years. The panel recognizes that there is heterogeneity across this risk group, and that some factors may be associated with an increased probability of near-term grade reclassification including high PSA density, a high number of positive cores (eg, ≥3), and high genomic risk (from tissue-based molecular tumor analysis). For some of these patients, upfront treatment with RP or prostate RT may be preferred based on shared decision-making.\n",
    "\n",
    "STATEMENT:\n",
    "According to the NCCN guidelines, the patient is a 55-year-old man.\n",
    "\n",
    "Is the given statement TRUE or FALSE based on question and context? The statement is: FALSE\n",
    "\n",
    "########\n",
    "'''\n",
    "\n",
    "FEW_SHOT_REWRITE = '''\n",
    "You are a helpful AI assistant answering medical and clinical questions.\n",
    "\n",
    "You will be given an input medical case, input question, a statement that is related to the question, and input context related to the statement. \n",
    "The statement was found not to be supported by the given input context when answering the given input question. \n",
    "Please rewrite the statement to be supported by the input context in terms of input question.\n",
    "\n",
    "########\n",
    "\n",
    "INPUT QUESTION:\n",
    "A patient with metastatic CRPC is unable to tolerate the standard 1000 mg/day dose of abiraterone due to financial constraints. What alternative dosing strategy could be considered?\n",
    "\n",
    "INPUT CONTEXT:\n",
    "Therefore, abiraterone can be given at 250 mg/day administered following a low-fat breakfast, as an alternative to the dose of 1000 mg/day after an overnight fast in patients who will not take or cannot afford the standard dose. The cost savings may reduce financial toxicity and improve adherence.\n",
    "\n",
    "STATEMENT:\n",
    "Taking abiraterone with a low-fat breakfast may help improve adherence.\n",
    "\n",
    "The rewritten statement is: Taking a lower dose of arbiteraone may help improve adherence due to a lower financial burden.\n",
    "\n",
    "########\n",
    "\n",
    "INPUT QUESTION:\n",
    "A patient with recurrent prostate cancer after radical prostatectomy shows a PSA level of 0.7 ng/ml and ISUP grade group 4. The physician is considering salvage radiotherapy RT. What do you recommend for this patient?\n",
    "\n",
    "INPUT CONTEXT:\n",
    "within two years of BCR showed that SRT was associated with a 3-fold increase in PCa-specific survival relative to those who received no salvage treatment (p < 0.001). Salvage RT has been shown to be effective mainly in patients with a short PSA-DT [960]. In a retrospective multi-centre study including 25,551 patients with at most one high-risk factor after RP (ISUP grade group 4-5 or pT3/4), initiating sRT above a PSA level of 0.25 ng/mL was associated with increased ACM-risk. After a median follow-up of six years, patients who received sRT at a PSA level >0.25 ng/mL had a significantly higher ACM-risk (AHR, 1.49; 95% CI, 1.11 to 2.00; P =.008) compared with men who received sRT when the PSA was ≤0.25 mg/mL [961]. For an overview of SRT see Table 6.4.3. The EAU BCR definitions have been externally validated and may be helpful for individualised treatment decisions [898, 903]. Despite the indication for salvage RT, a ‘wait and see‘ strategy remains an option for the EAU BCR ‘Low-Risk’ group [898,\n",
    "\n",
    "STATEMENT:\n",
    "The patient's current PSA level of 0.7 ng/ml falls within the range that is beneficial for SRT.\n",
    "\n",
    "The rewritten statement is: The patient's current PSA level of 0.7 ng/ml is above the threshold of 0.25 ng/ml, which has been associated with an increased risk of adverse outcomes; therefore, careful consideration should be given to initiating salvage radiotherapy (SRT) as it may still provide a benefit in this context.\n",
    "\n",
    "########\n",
    "\n",
    "INPUT QUESTION:\n",
    "A patient with a newly diagnosed prostate cancer has a clinical stage of T2c, 50% biopsy cores positive, PSA of 6 ng/ml and a Gleason score of 7a. How might the NCCN risk stratification schema categorize this patient?\n",
    "\n",
    "INPUT CONTEXT:\n",
    "Specifically, the NCCN Guidelines subdivide intermediate-risk disease into favourable and unfavourable intermediate-risk, with unfavourable features including ISUP grade group 3, and/or ≥ 50% positive systematic biopsy cores and/or at least two intermediate-risk factors. Intermediate risk factors are cT2b–cT2c, Grade Group 2 or, 3 PSA 10–20 ng/mL.\n",
    "\n",
    "STATEMENT:\n",
    "The patient would be categorized as intermediate-risk.\n",
    "\n",
    "The rewritten statement is: The patient would be categorized as intermediate risk, more specifically intermediate-unfavorable.\n",
    "\n",
    "########\n",
    "\n",
    "INPUT QUESTION:\n",
    "How do I treat a patient according to the ASCENDE-RT trial?\n",
    "\n",
    "INPUT CONTEXT:\n",
    "The randomized ASCENDE-RT trial compared two methods of dose escalation in 398 patients with intermediate- or high-risk prostate cancer: dose-escalated EBRT boost to 78 Gy or LDR brachytherapy boost. All patients were initially treated with 12 months of ADT and pelvic EBRT to 46 Gy.\n",
    "\n",
    "STATEMENT:\n",
    "According to the ASCENDE-RT trial, patients with biochemical recurrence (BCR) after radical prostatectomy should be treated with early salvage radiotherapy (SRT) combined with androgen deprivation therapy (ADT).\n",
    "\n",
    "The rewritten statement is: In the ASCENDE-RT trial, patients with intermediate or high-risk prostate cancer were treated with External Beam radiotherapy (EBRT) to the prostate and whole pelvis (46 Gy) followed by a Low Dose Rate (LDR) Brachytherapy boost. All patients received 12 months of ADT.\n",
    "\n",
    "########\n",
    "\n",
    "INPUT QUESTION:\n",
    "A 55-year-old man with a life expectancy of over 10 years has been diagnosed with very low-risk prostate cancer. What management strategy is recommended for him according to the NCCN guidelines?\n",
    "\n",
    "INPUT CONTEXT:\n",
    "Active surveillance is preferred for patients with very-low-risk prostate cancer and a life expectancy ≥10 years. (Observation is preferred for patients with a life expectancy <10 years and very-low-risk disease.) Active surveillance is preferred for most patients with low-risk prostate cancer and a life expectancy ≥10 years. The panel recognizes that there is heterogeneity across this risk group, and that some factors may be associated with an increased probability of near-term grade reclassification including high PSA density, a high number of positive cores (eg, ≥3), and high genomic risk (from tissue-based molecular tumor analysis). \n",
    "\n",
    "STATEMENT:\n",
    "According to the NCCN guidelines, the patient is a 55-year-old man.\n",
    "\n",
    "The rewritten statement is: The patient is a 55-year old man.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing and Database Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Traverse through the knowledge base directory, read all files with PaperMage (library for OCR), save them as JSON.\n",
    "\n",
    "PaperMage can recognize section names in scientific papers, page numbers, etc.\n",
    "'''\n",
    "\n",
    "from papermage.recipes import CoreRecipe\n",
    "\n",
    "#Load PaperMage and test with one document.\n",
    "recipe = CoreRecipe()\n",
    "doc = recipe.run(\"tests/fixtures/papermage.pdf\")\n",
    "\n",
    "\n",
    "# Traverse and run\n",
    "import os\n",
    "import json\n",
    "\n",
    "top_directory = \"/home/jvladika/LLM-KB/\"\n",
    "subfolders = os.listdir(top_directory)\n",
    "\n",
    "all_texts = list()\n",
    "all_names = list()\n",
    "\n",
    "for sub in subfolders[0:1]:\n",
    "    subname = os.path.join(top_directory, sub)\n",
    "\n",
    "    for filename in os.listdir(subname):\n",
    "   \n",
    "        print(filename)\n",
    "        all_names.append(filename)\n",
    "        \n",
    "        try:\n",
    "            filepath = str(os.path.join(subname, filename))\n",
    "            doc = recipe.run(filepath)\n",
    "            \n",
    "            with open('./LLM-KB/processed_docs/'+filename+'.json', 'w') as f_out:\n",
    "                json.dump(doc.to_json(), f_out, indent=4)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Once the JSONs are created, we can use them to create a vector database.\n",
    "'''\n",
    "\n",
    "import os\n",
    "\n",
    "top_directory = \"./Prostate_KB/\"\n",
    "filenames = os.listdir(top_directory)\n",
    "\n",
    "all_text = list()\n",
    "all_names = list()\n",
    "\n",
    "idx = 0\n",
    "subname = top_directory\n",
    "\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    all_names.append(filename)\n",
    "    \n",
    "    #try:\n",
    "    filepath = str(os.path.join(subname, filename))\n",
    "    \n",
    "    with open('./Prostate_KB/'+filename, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        all_text.append(f.read())\n",
    "    idx += 1\n",
    "\n",
    "    #except Exception as e:\n",
    "    #    print(e)\n",
    "    #    continue \n",
    "\n",
    "\n",
    "import sys\n",
    "import chromadb\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "'''\n",
    "Use the ChromaDB as a vector database to store embeddings, implementation through LangChain.\n",
    "'''\n",
    "\n",
    "documents = all_text\n",
    "\n",
    "# Chunk documents into pieces of 1024 characters (around 100-150 words)\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=200, separator=\" \")\n",
    "chunks_per_docs = list()\n",
    "for doc in documents:\n",
    "    splitted = text_splitter.split_text(doc)\n",
    "    chunks_per_docs.append(splitted)\n",
    "\n",
    "chunks_docs = list()\n",
    "cnt = 0\n",
    "for (chunks_doc, doc_name) in zip(chunks_per_docs, all_names):\n",
    "    doc_objects = text_splitter.create_documents(chunks_doc) \n",
    "    for do in doc_objects:\n",
    "        do.metadata = {\"source\" : doc_name}\n",
    "        #do.page_content = \"Prostate Cancer Guideline: \" + do.page_content\n",
    "    chunks_docs.extend(doc_objects)\n",
    "\n",
    "\n",
    "model_kwargs = {'device': 'mps'}\n",
    "\n",
    "# Choose the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"pritamdeka/S-PubMedBert-MS-MARCO-SCIFACT\", model_kwargs=model_kwargs)\n",
    "\n",
    "from copy import deepcopy\n",
    "prostate_chunks_list = deepcopy(chunks_docs)\n",
    "\n",
    "# Load it into Chroma DB\n",
    "prostate_db = Chroma.from_documents(prostate_chunks_list, embedding_function, persist_directory=\"vector_data/prostate_db_9\")\n",
    "\n",
    "\n",
    "##### Same for Breast KB\n",
    "\n",
    "top_directory = \"./Breast_KB/\"\n",
    "filenames = os.listdir(top_directory)\n",
    "\n",
    "all_text = list()\n",
    "all_names = list()\n",
    "idx = 0\n",
    "subname = top_directory\n",
    "\n",
    "for filename in filenames:    \n",
    "    print(filename)\n",
    "    all_names.append(filename)\n",
    "    \n",
    "    #try:\n",
    "    filepath = str(os.path.join(subname, filename))\n",
    "    \n",
    "    with open('./Breast_KB/'+filename, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        all_text.append(f.read())\n",
    "\n",
    "    idx += 1\n",
    "\n",
    "breast_docs = all_text\n",
    "\n",
    "# Chunk documents into pieces of 1024 characters (around 100-150 words)\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=200, separator=\" \")\n",
    "chunks_per_docs = list()\n",
    "for doc in breast_docs:\n",
    "    splitted = text_splitter.split_text(doc)\n",
    "    chunks_per_docs.append(splitted)\n",
    "\n",
    "cnt = 0\n",
    "chunks_docs = list()\n",
    "for (chunks_doc, doc_name) in zip(chunks_per_docs, all_names):\n",
    "    doc_objects = text_splitter.create_documents(chunks_doc) \n",
    "    for do in doc_objects:\n",
    "        do.metadata = {\"source\" : doc_name}\n",
    "        #do.page_content = \"Breast Cancer Guideline: \" + do.page_content\n",
    "    chunks_docs.extend(doc_objects)\n",
    "\n",
    "\n",
    "model_kwargs = {'device': 'mps'}\n",
    "\n",
    "# Choose the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"pritamdeka/S-PubMedBert-MS-MARCO-SCIFACT\", model_kwargs=model_kwargs)\n",
    "\n",
    "from copy import deepcopy\n",
    "breast_chunks_list = deepcopy(chunks_docs)\n",
    "\n",
    "# Load it into Chroma DB\n",
    "breast_db = Chroma.from_documents(breast_chunks_list, embedding_function, persist_directory=\"vector_data/breast_db_9\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If chunking already done and stored, load persisted data into the vector databases.\n",
    "'''\n",
    "\n",
    "import chromadb\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "model_kwargs = {'device': 'mps'}\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"pritamdeka/S-PubMedBert-MS-MARCO-SCIFACT\", model_kwargs=model_kwargs)\n",
    "\n",
    "\n",
    "prostate_db = Chroma(persist_directory=\"vector_data/prostate_db_6\", embedding_function=embedding_function)\n",
    "\n",
    "breast_db = Chroma(persist_directory=\"vector_data/breast_db_6\", embedding_function=embedding_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Answering and Fact Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load the datasets of questions and answers about prostate/breast cases.\n",
    "'''\n",
    "\n",
    "df_breast = pd.read_csv(\"QA_pairs_breast_RA.csv\")\n",
    "df_breast = df_breast[df_breast.human_answer.notna()]\n",
    "breast_questions = df_breast.question.tolist()\n",
    "breast_answers = df_breast.human_answer.tolist()\n",
    "\n",
    "df_prostate = pd.read_csv(\"QA_pairs_excel_JP.csv\")\n",
    "df_prostate = df_prostate[df_prostate.human_answer.notna()]\n",
    "prostate_questions = df_prostate.question.tolist()\n",
    "prostate_answers = df_prostate.human_answer.tolist()\n",
    "\n",
    "\n",
    "\n",
    "### Template for QA generation with few-shot examples from first four questions\n",
    "\n",
    "\n",
    "FEW_SHOT_TEMPLATE = '''\n",
    "You are a helpful AI assistant answering medical and clinical questions. Here are some examples of questions and answers.\n",
    "\n",
    "**Few-Shot Examples:**'''\n",
    "\n",
    "FEW_SHOT_TEMPLATE += f'''\n",
    "    **Question:** {prostate_questions[0]}\n",
    "    **Answer:** {prostate_answers[0]}\n",
    "'''\n",
    "\n",
    "FEW_SHOT_TEMPLATE += f'''\n",
    "    **Question:** {prostate_questions[1]}\n",
    "    **Answer:** {prostate_answers[1]}\n",
    "'''\n",
    "\n",
    "FEW_SHOT_TEMPLATE += f'''\n",
    "    **Question:** {prostate_questions[2]}\n",
    "    **Answer:** {prostate_answers[2]}\n",
    "'''\n",
    "\n",
    "FEW_SHOT_TEMPLATE += f'''\n",
    "    **Question:** {prostate_questions[3]}\n",
    "    **Answer:** {prostate_answers[3]}\n",
    "'''\n",
    "\n",
    "FEW_SHOT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate answers to questions based on few-shot prompt.\n",
    "'''\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def get_system_prompt(query) -> str:\n",
    "\n",
    "    prompt = FEW_SHOT_TEMPLATE + '''\n",
    "    ---\n",
    "    Now, please answer the following question based on the input context provided. The context can be noisy. Please only use the information from the context. \n",
    "    Please provide a factual and clear answer, similar in style and length to the examples above.\n",
    "    \n",
    "    **Question:** '''+query + \"\\n\\n\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def get_chat_prompt(input_context: str, query, system_message: bool = True) -> list:\n",
    "    message = []\n",
    "\n",
    "    if system_message:\n",
    "        message.append({\"role\": \"system\", \"content\": f\"{get_system_prompt(query)}\"})\n",
    "\n",
    "    message.append({\"role\": \"user\", \"content\": f\"\"\"INPUT CONTEXT: {input_context}\n",
    "    \n",
    "            **Answer:**: \"\"\"})\n",
    "    return message\n",
    "\n",
    "\n",
    "apikey = 'KEY'\n",
    "client = OpenAI(api_key=apikey)\n",
    "\n",
    "\n",
    "def query_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", # set model version\n",
    "        max_tokens = 4096,\n",
    "        messages=prompt, # provide prompt in chat format\n",
    "        temperature=0) # set model temperature = 0\n",
    "    return response\n",
    "\n",
    "\n",
    "all_responses = list()\n",
    "\n",
    "for question in prostate_questions:\n",
    "    query = question\n",
    "\n",
    "    ## Get top 7 chunks (most similar to the query) from vector DB, and concatenate into context.\n",
    "    results = prostate_db.search(query, \"mmr\", k=7)\n",
    "    context = \"\"\n",
    "    for r in results:\n",
    "        context += r.page_content\n",
    "        context += \"\\n\"\n",
    "    \n",
    "    prompt = get_chat_prompt(context, query)\n",
    "    response = query_gpt(prompt=prompt)\n",
    "    result = response.choices[0].message.content.strip()\n",
    "\n",
    "    all_responses.append(result)\n",
    " \n",
    "''' \n",
    "for question in breast_questions:\n",
    "    query = question\n",
    "    results = breast_db.search(query, \"similarity\", k=7)\n",
    "    context = \"\"\n",
    "    for r in results:\n",
    "        context += r.page_content\n",
    "        context += \"\\n\"\n",
    "    \n",
    "    prompt = get_IE_zero_shot_chat_prompt(context, query)\n",
    "    response = query_gpt(prompt=prompt)\n",
    "    result = response.choices[0].message.content.strip()\n",
    "\n",
    "    all_responses.append(result)\n",
    "''' \n",
    "\n",
    "print(all_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Split the responses into atomic facts based on the few-shot examples.\n",
    "'''\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=apikey)\n",
    "\n",
    "def get_atomic_facts(resp):\n",
    "    \n",
    "    def get_system_prompt() -> str:\n",
    "    \n",
    "        prompt = '''\n",
    "        Please breakdown the following text into independent facts (use -- as fact separator, do not use numbered list):\n",
    "        For a 72-year-old male patient with locally advanced prostate cancer (cT3/cT4) treated with EBRT, the recommended duration of androgen deprivation therapy (ADT) is two to three years.\n",
    "        -- The patient is a 72-year-old male.\n",
    "        -- The patient has locally advanced prostate cancer.\n",
    "        -- The prostate cancer is classified as cT3/cT4.\n",
    "        -- The patient was treated with EBRT (External Beam Radiation Therapy).\n",
    "        -- The recommended duration of androgen deprivation therapy (ADT) for this patient is two to three years.\n",
    "        \n",
    "        Please breakdown the following text into independent facts (use -- as fact separator, do not use numbered list):\n",
    "        Androgen deprivation therapy (ADT) should be included in the treatment of a patient with clinically lymph node-positive prostate cancer (cN1) receiving external beam radiation therapy (EBRT). The recommended duration of ADT is 2 to 3 years. Additionally, in patients with good WHO performance status and without significant cardiovascular disease, the use of Abiraterone can be considered for a total of 2 years alongside ADT.\n",
    "        -- Androgen deprivation therapy (ADT) should be included in the treatment of a patient with clinically lymph node-positive prostate cancer (cN1).\n",
    "        -- The patient is receiving external beam radiation therapy (EBRT).\n",
    "        -- The recommended duration of ADT is 2 to 3 years.\n",
    "        -- In patients with good WHO performance status, the use of Abiraterone can be considered.\n",
    "        -- The use of Abiraterone can be considered for a total of 2 years alongside ADT.\n",
    "        -- Patients should not have significant cardiovascular disease for the use of Abiraterone to be considered.\n",
    "\n",
    "        Please breakdown the following text into independent facts (use -- as fact separator, do not use numbered list):\n",
    "        For a patient with high-risk prostate cancer undergoing dose-escalated external beam radiation therapy (EBRT), it is recommended to administer androgen deprivation therapy (ADT) for 2 to 3 years concurrently.\n",
    "        -- For a patient with high-risk prostate cancer, it is recommended to administer androgen deprivation therapy (ADT).\n",
    "        -- Androgen deprivation therapy (ADT) is recommended for 2 to 3 years.\n",
    "        -- Androgen deprivation therapy (ADT) is recommended to be administered concurrently with dose-escalated external beam radiation therapy (EBRT).\n",
    "        -- Dose-escalated external beam radiation therapy (EBRT) is a treatment for high-risk prostate cancer.\n",
    "        \n",
    "        Please breakdown the following text into independent facts (use -- as fact separator, do not use numbered list):\n",
    "        Fertility and fertility preservation should be discussed with the premenopausal woman before the initiation of any systemic treatment. This is important to address the potential impact of cancer treatment on fertility and to explore options such as egg or embryo freezing, ovarian suppression, or other fertility preservation strategies.\n",
    "        -- Fertility and fertility preservation should be discussed with the premenopausal woman before starting any systemic treatment.\n",
    "        -- Cancer treatment has a potential impact on fertility.  \n",
    "        -- Discussing fertility and fertility preservation addresses the potential impact of cancer treatment on fertility.\n",
    "        -- Options for fertility preservation include egg or embryo freezing, ovarian suppression, or other strategies.\n",
    "        -- The discussion about fertility and fertility preservation is important before initiating systemic treatment.\n",
    "\n",
    "        Please breakdown the following text into independent facts (use -- as fact separator, do not use numbered list):\n",
    "        For a 60-year-old woman with HR-positive, HER2-negative early breast cancer with uncertainty about the need for adjuvant chemotherapy, gene expression assays and endocrine response assessment in the preoperative setting can be used to help guide the decision. These tests help assess the benefit of chemotherapy based on the biological characteristics of the tumor.\n",
    "        -- The patient is a 60-year-old woman.\n",
    "        -- The patient has HR-positive, HER2-negative early breast cancer.\n",
    "        -- There is uncertainty about the need for adjuvant chemotherapy.\n",
    "        -- Gene expression assays and endocrine response assessment can be used in the preoperative setting to help guide the decision regarding chemotherapy.\n",
    "        -- Gene expression assays and endocrine response assessment help assess the benefit of chemotherapy.\n",
    "        -- These tests evaluate the biological characteristics of the tumor.​\n",
    "        \n",
    "        Please breakdown the following text into independent facts (use -- as fact separator, do not use numbered list): \\n''' + resp + '''\n",
    "        -- \n",
    "        '''\n",
    "        return prompt\n",
    "    \n",
    "    \n",
    "    def get_chat_prompt(input_context: str, system_message: bool = True) -> list:\n",
    "        message = []\n",
    "    \n",
    "        if system_message:\n",
    "            message.append({\"role\": \"system\", \"content\": f\"{get_system_prompt()}\"})\n",
    "    \n",
    "        message.append({\"role\": \"user\", \"content\": f\"\"\"{input_context}\n",
    "                \"\"\"})\n",
    "        return message\n",
    "    \n",
    "    \n",
    "    def query_gpt(prompt):\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            max_tokens = 4096,\n",
    "            messages=prompt,\n",
    "            temperature=0) \n",
    "        return response\n",
    "    \n",
    "    #Use the generated response as the input\n",
    "    prompt = get_chat_prompt(\"\")\n",
    "    \n",
    "    response = query_gpt(prompt=prompt)\n",
    "    result = response.choices[0].message.content.strip()\n",
    "    #print(\"prediction:\", result)\n",
    "\n",
    "    atoms = result.split(\"--\")\n",
    "    atoms = [a.strip() for a in atoms]\n",
    "    return result, atoms\n",
    "\n",
    "all_atoms = list()\n",
    "atom_results = list()\n",
    "for response in all_responses:\n",
    "    result, atoms = get_atomic_facts(response)\n",
    "    atom_results.append(result)\n",
    "    all_atoms.append(atoms)\n",
    "\n",
    "print(all_atoms)\n",
    "\n",
    "cleaned_atoms = [ats[1:] for ats in all_atoms]\n",
    "cleaned_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Determine which atomic facts are correct and which are incorrect.\n",
    "'''\n",
    "\n",
    "client = OpenAI(api_key=apikey)\n",
    "new_atoms = cleaned_atoms\n",
    "\n",
    "\n",
    "all_contexts = list()\n",
    "atom_context_results = list()\n",
    "\n",
    "question_idx = 0\n",
    "for atom_facts in new_atoms:\n",
    "    instance_contexts = list()\n",
    "    question = questions[question_idx]\n",
    "    atom_results = list()\n",
    "    \n",
    "    for atom in atom_facts:\n",
    "        ar = list()\n",
    "        full_context = \"\"\n",
    "        \n",
    "        ## Find top 7 chunks (most similar to the atom fact) from the vector DB and concatenate them.\n",
    "        results = prostate_db.search(question + \" \" + atom, \"similarity\", k=7)\n",
    "        ar.extend(results)\n",
    "        for chunk in results:\n",
    "            full_context += chunk.page_content.replace(\"\\n\", \" \")\n",
    "            full_context += \" | \"\n",
    "\n",
    "        atom_results.append(ar)\n",
    "        instance_contexts.append(full_context)\n",
    "        \n",
    "    atom_context_results.append(atom_results)\n",
    "    all_contexts.append(instance_contexts)\n",
    "    question_idx += 1\n",
    "    \n",
    "\n",
    "\n",
    "def get_chat_prompt(question, context, atom, full_response) -> str:\n",
    "\n",
    "    prompt = FEW_SHOT_ATOMIC_VERDICT + '''\n",
    "    ########\n",
    "\n",
    "    INPUT QUESTION\n",
    "    ''' + question + '''\n",
    "\n",
    "    INPUT CONTEXT \n",
    "    ''' + context + '''\n",
    "    \n",
    "    STATEMENT\n",
    "    ''' + atom + '''\n",
    "\n",
    "    Is the given statement TRUE or FALSE based on question and context? The statement is: '''\n",
    "\n",
    "    message = []\n",
    "\n",
    "    message.append({\"role\": \"user\", \"content\": prompt})\n",
    "    return message\n",
    "\n",
    "\n",
    "def query_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", # set model version\n",
    "        max_tokens = 4096,\n",
    "        messages=prompt, # provide prompt in chat format\n",
    "        temperature=0) # set model temperature = 0\n",
    "    return response\n",
    "\n",
    "\n",
    "all_verdicts = list()\n",
    "question_idx = 0\n",
    "for atom_facts in new_atoms:\n",
    "    instance_results = list()\n",
    "    \n",
    "    instance_contexts = all_contexts[question_idx]\n",
    "    question = questions[question_idx]\n",
    "    full_response = all_responses[question_idx]\n",
    "\n",
    "    atom_idx = 0\n",
    "    for atom in atom_facts:\n",
    "        atom_context = instance_contexts[atom_idx]\n",
    "        prompt = get_chat_prompt(question, atom_context, atom, full_response)\n",
    "        \n",
    "        response = query_gpt(prompt=prompt)\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        instance_results.append(result)  \n",
    "        atom_idx += 1\n",
    "    \n",
    "    all_verdicts.append(instance_results)\n",
    "    question_idx += 1\n",
    "    \n",
    "\n",
    "## get overview of final results\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "a = np.array(flatten(all_verdicts))\n",
    "print(np.unique(a, return_counts=True))\n",
    "\n",
    "for idx, av in enumerate(all_verdicts):\n",
    "    print(idx, av)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Rewrite those atoms determined to be incorrect in the previous step, based on the newly retrieved context from previous step.\n",
    "'''\n",
    "\n",
    "def get_chat_prompt(question, context, atom) -> str:\n",
    "\n",
    "    prompt = FEW_SHOT_REWRITE + '''\n",
    "    ########\n",
    "    \n",
    "    INPUT QUESTION:\n",
    "    ''' + question + '''\n",
    "\n",
    "    INPUT CONTEXT:\n",
    "    ''' + context + '''\n",
    "    \n",
    "    STATEMENT:\n",
    "    ''' + atom + '''\n",
    "\n",
    "    The rewritten statement is: '''\n",
    "\n",
    "    message = []\n",
    "\n",
    "    message.append({\"role\": \"user\", \"content\": prompt})\n",
    "    return message\n",
    "\n",
    "\n",
    "def query_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", # set model version\n",
    "        max_tokens = 4096,\n",
    "        messages=prompt, # provide prompt in chat format\n",
    "        temperature=0) # set model temperature = 0\n",
    "    return response\n",
    "\n",
    "\n",
    "all_corrections = list()\n",
    "question_idx = 0\n",
    "for atom_facts in new_atoms:\n",
    "    instance_results = list()\n",
    "    \n",
    "    instance_contexts = all_contexts[question_idx]\n",
    "    question = questions[question_idx]\n",
    "\n",
    "    atom_idx = 0\n",
    "    for atom in atom_facts:\n",
    "        verdict = all_verdicts[question_idx][atom_idx]\n",
    "        if verdict == \"TRUE\":\n",
    "            atom_idx += 1\n",
    "            continue\n",
    "        \n",
    "        atom_context = instance_contexts[atom_idx]\n",
    "        prompt = get_chat_prompt(question, atom_context, atom)\n",
    "        \n",
    "        response = query_gpt(prompt=prompt)\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        instance_results.append(result)  \n",
    "        print(prompt)\n",
    "        print(\"RESULT: \", result)\n",
    "        atom_idx += 1\n",
    "    \n",
    "    all_corrections.append(instance_results)\n",
    "    question_idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Rewrite the initial response based on the newly corrected atomic facts. \n",
    "'''\n",
    "\n",
    "\n",
    "def get_chat_prompt(question, old_response, incorrect, corrected) -> str:\n",
    "\n",
    "    prompt = '''\n",
    "    You are a helpful AI assistant answering medical and clinical questions.\n",
    "\n",
    "    You will be given an input question, old response to the question, and statements from the response found to be incorrect.\n",
    "    You will also be given the corrected versions of the input statements. \n",
    "    \n",
    "    Please rewrite the response to remove the incorrect claims and incorporate the corrected statements. You can rewrite it to make it more natural.\n",
    "    \n",
    "    INPUT QUESTION\n",
    "    ''' + question + '''\n",
    "\n",
    "    OLD RESPONSE\n",
    "    ''' + old_response + '''\n",
    "\n",
    "    INCORRECT STATEMENTS \n",
    "    ''' + incorrect +'''\n",
    "    \n",
    "    CORRECTED STATEMENTS\n",
    "    ''' + corrected + '''\n",
    "\n",
    "    The rewritten response is: '''\n",
    "\n",
    "    message = []\n",
    "\n",
    "    message.append({\"role\": \"user\", \"content\": prompt})\n",
    "    return message\n",
    "\n",
    "\n",
    "def query_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", # set model version\n",
    "        max_tokens = 4096,\n",
    "        messages=prompt, # provide prompt in chat format\n",
    "        temperature=0) # set model temperature = 0\n",
    "    return response\n",
    "    \n",
    "client = OpenAI(api_key=apikey)\n",
    "\n",
    "\n",
    "new_responses = list()\n",
    "question_idx = 0\n",
    "for atom_facts in new_atoms:\n",
    "    if len(all_corrections[question_idx]) == 0:\n",
    "        new_responses.append(all_responses[question_idx])\n",
    "        question_idx += 1\n",
    "        continue\n",
    "    \n",
    "    instance_results = list()\n",
    "    \n",
    "    corrected = all_corrections[question_idx]\n",
    "    question = questions[question_idx]\n",
    "    old_response = all_responses[question_idx]\n",
    "\n",
    "    try:\n",
    "        atom_idx = 0\n",
    "        incorrect = list()\n",
    "        for atom in atom_facts:\n",
    "            if all_verdicts[question_idx][atom_idx] == \"FALSE\":\n",
    "                incorrect.append(atom)\n",
    "            atom_idx += 1\n",
    "    except:\n",
    "        print(\"EXCEPTION!!\")\n",
    "        print(question_idx, atom_idx)\n",
    "        \n",
    "    prompt = get_chat_prompt(question, old_response, str(incorrect), str(corrected))\n",
    "\n",
    "    print(\"Question: \", question, \"\\n\\n Initial response: \", old_response, \"\\n\\n Incorrect atomic facts: \", str(incorrect), \n",
    "          \"\\n\\n Corrected atomic facts: \", str(corrected), \"\\n ====\\n\\n\" )\n",
    "    \n",
    "    response = query_gpt(prompt=prompt)\n",
    "    result = response.choices[0].message.content.strip()\n",
    "    new_responses.append(result)\n",
    "    question_idx += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
